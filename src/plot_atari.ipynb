{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../logs\"\n",
    "exps = os.listdir(data_path)\n",
    "results = {}\n",
    "\n",
    "for exp in exps:\n",
    "    try:\n",
    "        nested_ = os.listdir(os.path.join(data_path, exp))\n",
    "        file = os.path.join(data_path, exp, nested_[0], \"train.log\")\n",
    "        data = pd.read_csv(file)\n",
    "\n",
    "        # take all but last _s1, or _s2, or _s3 which are the seeds\n",
    "        exp_name = \"_\".join(exp.split(\"_\")[:-1])\n",
    "        if exp_name not in results:\n",
    "            results[exp_name] = []\n",
    "        \n",
    "        results[exp_name].append(data[\"episode_reward\"][100:])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare summary table\n",
    "summary_data = {\n",
    "    \"Experiment\": [],\n",
    "    \"Mean Reward\": [],\n",
    "    \"Std Dev Reward\": [],\n",
    "    \"Num Seeds\": []\n",
    "}\n",
    "\n",
    "for exp_name, rewards in results.items():\n",
    "    try:\n",
    "        all_rewards = np.concatenate(rewards)\n",
    "        summary_data[\"Experiment\"].append(exp_name)\n",
    "        summary_data[\"Mean Reward\"].append(np.mean(all_rewards))\n",
    "        summary_data[\"Std Dev Reward\"].append(np.std(all_rewards))\n",
    "        summary_data[\"Num Seeds\"].append(len(rewards))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values(by=\"Mean Reward\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = summary_df.sort_values(by=\"Experiment\")\n",
    "summary_df.to_csv(\"experiment_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df[\"Algorithm\"] = summary_df[\"Experiment\"].apply(lambda x: x.split(\"_\")[2])\n",
    "summary_df[\"Environment\"] = summary_df[\"Experiment\"].apply(lambda x: x.split(\"_\")[1].replace(\"-v5\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------------------------------+----------------------------------------+-----------------------------------------+--------------------------------------------+-----------------------------------------+-----------------------------------------+-----------------------------------------+------------------------------------------+\n",
      "|   |   Environment    |              disagreement               |                  e3b                   |                extrinsic                |                    icm                     |              pseudocounts               |                   re3                   |                  ride                   |                   rnd                    |\n",
      "+---+------------------+-----------------------------------------+----------------------------------------+-----------------------------------------+--------------------------------------------+-----------------------------------------+-----------------------------------------+-----------------------------------------+------------------------------------------+\n",
      "| 0 |     Gravitar     |  636.627766801728 ± 299.9302832439733   | 549.512960436562 ± 237.91192688027803  | 1183.6870022870685 ± 700.8991858097623  |   199.80705693664797 ± 80.65982196129839   |  228.371699669967 ± 97.58891625245637   | 127.35664609110968 ± 63.159053851830635 | 334.16299559471366 ± 117.96141318695516 |  883.8867321934969 ± 396.42004512843107  |\n",
      "| 1 | MontezumaRevenge |                0.0 ± 0.0                | 1.0264379414732594 ± 4.733877234250375 | 128.64430121742961 ± 224.37999020907083 | 0.005287119988250845 ± 0.22987658916196377 |                0.0 ± 0.0                |  8.839348665435622 ± 16.59638098466911  |                0.0 ± 0.0                |  92.40740169622205 ± 120.03184853944488  |\n",
      "| 2 |    PrivateEye    | 29.076797249715824 ± 165.59635589863132 |  71.8891891891892 ± 100.0345012237024  |  85.97887382516842 ± 34.6673498517611   |   57.69901302053676 ± 51.336832362308165   | 60.660906515580734 ± 413.42342550114046 | 43.30053154205608 ± 1123.5695118580502  |  26.99960367501351 ± 38.41228185657482  | -15.051105164868861 ± 183.60585137687977 |\n",
      "| 3 |     Seaquest     |  11718.94545236453 ± 8607.060031871075  | 3657.3595651808946 ± 2904.815676427424 | 1600.6962391513982 ± 356.11202345331355 |   3041.717014645263 ± 1913.9343506587973   |  604.7874797213475 ± 136.2918852193787  | 692.7720219078046 ± 181.30947163765876  | 1018.6809581320451 ± 343.67375316550283 |  5815.883297401566 ± 2335.5052924014726  |\n",
      "| 4 |     Venture      | 399.0074449076831 ± 273.96006293825604  | 336.2008000571469 ± 444.5515489658191  |  324.741096306105 ± 558.0891205225765   |                 0.0 ± 0.0                  |                0.0 ± 0.0                | 0.2005683228956879 ± 2.1505780666384786 | 192.02224757558471 ± 353.2242339639359  |  574.8020384163074 ± 178.1350321195756   |\n",
      "+---+------------------+-----------------------------------------+----------------------------------------+-----------------------------------------+--------------------------------------------+-----------------------------------------+-----------------------------------------+-----------------------------------------+------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "table = summary_df.pivot_table(index='Environment', \n",
    "                         columns='Algorithm', \n",
    "                         values=['Mean Reward', 'Std Dev Reward'],\n",
    "                         aggfunc='first')\n",
    "\n",
    "# Create a new DataFrame to format the mean ± std\n",
    "formatted_table = pd.DataFrame()\n",
    "\n",
    "# Iterate over each column (algorithm) and create the formatted strings\n",
    "for col in table.columns.levels[1]:  # Iterate over algorithms\n",
    "    mean_col = ('Mean Reward', col)\n",
    "    std_col = ('Std Dev Reward', col)\n",
    "    formatted_table[col] = table[mean_col].astype(str) + \" ± \" + table[std_col].astype(str)\n",
    "\n",
    "# Reset index for better readability\n",
    "formatted_table.reset_index(inplace=True)\n",
    "\n",
    "# Display the final table\n",
    "print(tabulate(formatted_table, headers='keys', tablefmt='pretty'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllte",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
